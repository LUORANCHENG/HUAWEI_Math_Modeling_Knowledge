# 2. 为什么选用SVM算法

基于对论文《出血性脑卒中临床智能诊疗建模》的分析，作者选用SVM算法的原因可以从以下几个方面来理解：

## 2.1 算法特性适合问题特点

### 2.1.1 处理混合数据类型的能力
论文中提到，原始数据存在着一定量的**离散变量**，数据类型包括：
- 字符型变量（如性别、血压）
- 整型变量  
- 浮点型变量

SVM算法能够很好地处理这种**混合数据类型**，这是选择SVM的重要原因之一。

### 2.1.2 处理类别不平衡问题
在问题一的血肿扩张预测任务中，数据存在明显的类别不平衡：
- 发生血肿扩张的患者：23人
- 未发生血肿扩张的患者：77人

SVM算法在处理**类别偏差**方面具有一定的优势，这使得它成为合适的选择。

## 2.2 算法的技术优势

### 2.2.1 强大的分类能力
SVM可以处理多种类型的数据分布：
- **线性可分数据集**：通过硬间隔最大化，学习线性分类器
- **近似线性可分数据集**：通过软间隔最大化，学习线性分类器  
- **不可分数据集**：通过核技巧和软间隔最大化，学习非线性分类器

这种灵活性使得SVM能够适应不同的数据特征。

### 2.2.2 置信度输出机制
论文中特别提到了SVM的置信度计算方法：
> "在SVM中，决策函数的值取决于样本与决策边界(超平面)的距离。正类样本距离决策边界越远，负类样本距离决策边界越远，它们的决策函数值就越大。因此，在本文中，将决策函数的值表示样本被分类为正类的置信度。"

这种基于**几何距离**的置信度计算方式，为概率预测提供了理论基础。

## 2.3 实验性能表现

### 2.3.1 在血肿扩张预测任务中的表现
根据论文表6的消融实验结果：
- SVM (实验组B)：MAE=0.3232, MSE=0.1432, R²=0.2277
- 相比KNN (实验组A)：MAE=0.3107, MSE=0.1606, R²=0.1344

SVM在MSE和R²指标上优于KNN，显示出更好的预测性能。

### 2.3.2 在预后预测任务中的表现
在问题三的90天mRS评分预测中：

**未加入随访数据时**：
- SVM精确率：0.763，召回率：0.691
- 在四种基础算法中排名第二，仅次于梯度提升决策树

**加入随访数据后**：
- SVM精确率：0.793，召回率：0.831
- 性能进一步提升，召回率甚至超过了梯度提升决策树

## 2.4 在集成学习中的作用

### 2.4.1 作为基学习器的价值
在Stacking集成模型中，SVM被选为基学习器之一：
```python
estimators = [('rf', RandomForestClassifier(n_jobs=-1)), 
              ('svc', SVC(kernel="rbf", probability=True)), 
              ('gdbt', GradientBoostingClassifier()),
              ('knn', KNeighborsClassifier(n_jobs=-1))]
```

SVM的**多样性**为集成学习提供了不同的视角，有助于提高整体模型的泛化能力。

### 2.4.2 概率输出的重要性
论文中使用`SVC(kernel="rbf", probability=True)`，这表明作者需要SVM输出概率值而非仅仅的分类结果，这对于：
- 血肿扩张的**概率预测**
- 集成学习中的**软投票**机制
都是必要的。

## 2.5 总结

作者选择SVM算法的主要原因包括：

1. **数据适应性强**：能处理混合数据类型和类别不平衡问题
2. **理论基础扎实**：基于几何距离的置信度计算具有可解释性
3. **性能表现良好**：在多个任务中都展现出竞争力的性能
4. **集成学习价值**：作为基学习器提供模型多样性
5. **概率输出能力**：满足概率预测任务的需求

虽然SVM在单独使用时性能不是最佳的，但其稳定性和多样性使其成为整个建模框架中不可或缺的组成部分。 