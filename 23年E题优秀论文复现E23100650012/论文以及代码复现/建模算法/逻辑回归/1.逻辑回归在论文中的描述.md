# 逻辑回归在论文中的描述

## 1. 在Stacking集成算法中的应用

在问题三的求解中，论文采用了基于Stacking的分类模型来预测患者90天mRS评分。在该框架中，逻辑回归作为元学习器（meta-learner）被使用。

### Stacking方法描述

Stacking 方法是一种层级模型集成框架,它在各种机器学习任务中具有提高模型准确性和增强泛化能力的潜力。该方法通过组合多个基学习器来执行学习任务。以两层集成为例,首先,将数据集分为训练集和测试集。使用训练集来训练多个初级学习器,这些初级学习器可以是不同的机器学习模型。然后,使用这些初级学习器来对测试集进行预测,并将它们的输出值作为下一阶段训练的输入。最终,使用测试集的真实标签作为输出值,用于训练次级学习器,也称为元学习器 (meta-learner)。Stacking 的关键思想在于,由于初级学习器和次级学习器在两个不同的数据集上进行训练,可以一定程度上防止过拟合。这种分层结构有助于提高模型的性能,使模型能够更好地捕获数据的复杂关系,提高泛化能力。

### 代码实现中的应用

在论文的源程序中，逻辑回归作为Stacking分类器的最终估计器（final_estimator）：

```python
estimators = [('rf', RandomForestClassifier(n jobs=-1)), ('svc',
  SVC(kernel="rbf", probability =
   True)), ('gdbt', GradientBoostingClassifier()),
          ('knn',KNeighborsClassifier(n_jobs=-1))]
cls model = [
   KNeighborsClassifier(n_jobs=-1),
   SVC(kernel="rbf", probability = True),
  RandomForestClassifier(n_jobs=-1),
   GradientBoostingClassifier(),
   StackingClassifier(estimators=estimators, final estimator=LogisticRegression()
                     ),
]
```

## 2. 模型选择理由

根据论文描述，对于本题，其实是需要建立一个七分类模型。但难点在于数据量较少，若使用特征提取能力强大的神经网络建模，有可能出现过拟合的情况，因此需要建立一个表达能力强同时容量较少的模型。本文使用 K 则交叉验证建立基于 Stacking 的回归模型。

## 3. 实验结果

针对患者 90 天 mRS 评分的预测问题，论文对比了五种方法：

| 分类模型     | 精确率   | 召回率   |
|----------|-------|-------|
| k 近邻算法   | 0.652 | 0.568 |
| 支持向量机分类器 | 0.763 | 0.691 |
| 随机森林分类器  | 0.738 | 0.678 |
| 梯度提升决策树  | 0.781 | 0.731 |
| Stacking | 0.835 | 0.821 |

基于 Stacking 的分类模型表现出了最佳的效果,准确和召回均高于 80%。 