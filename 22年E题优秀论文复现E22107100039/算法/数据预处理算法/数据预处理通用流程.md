# 数据预处理通用流程模板

## 概述
本模板基于2022年华为杯数学建模竞赛E题优秀论文E22107100039《草原放牧策略研究》中的数据预处理方法总结而成，提供了一套系统性的数据预处理流程，适用于时间序列预测、机器学习建模等多种场景。

## 1. 数据探索与分析阶段

### 1.1 数据基本信息统计
```python
# 数据基本信息
data.describe()  # 描述性统计
data.info()      # 数据类型和缺失值信息
data.shape       # 数据维度
```

### 1.2 数据可视化分析
- **箱线图分析**：观察数据分布、异常值和趋势
- **直方图分析**：查看数据频率分布
- **散点图分析**：探索变量间关系
- **柱状图分析**：统计分类变量分布

### 1.3 相关性分析
```python
# Pearson相关系数分析
pearson_corr = data.corr()
# Spearman相关系数分析  
spearman_corr = data.corr(method="spearman")
# 热力图可视化
sns.heatmap(pearson_corr, annot=True)
```

## 2. 数据清洗阶段

### 2.1 缺失值处理
```python
# 检查缺失值
data.isnull().sum()
# 处理方式：
# 方式1：删除缺失值过多的列
# 方式2：用0填充（适用于计数类数据）
# 方式3：用均值/中位数填充
# 方式4：用前值填充（时间序列）
```

### 2.2 重复值处理
```python
# 检查重复值
data.duplicated().sum()
# 删除重复值
data = data.drop_duplicates()
```

### 2.3 异常值处理
- 基于业务逻辑判断
- 基于统计方法（3σ原则、四分位数）
- 根据数据分布特征决定保留或删除

### 2.4 无效特征删除
- 删除相关性为1的重复特征
- 删除无变化的常量特征
- 删除缺失值过多的特征

## 3. 数据转换阶段

### 3.1 时间序列数据处理
#### 3.1.1 滑动窗口转换
```python
def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
    """
    将时间序列数据转换为监督学习问题
    """
    n_vars = 1 if type(data) is list else data.shape[1]
    df = pd.DataFrame(data)
    cols, names = list(), list()
    
    # 输入序列(t-n, ... t-1)
    for i in range(n_in, 0, -1):
        cols.append(df.shift(i))
        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
    
    # 预测序列(t, t+1, ... t+n)
    for i in range(0, n_out):
        cols.append(df.shift(-i))
        if i == 0:
            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
        else:
            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
    
    # 拼接
    agg = pd.concat(cols, axis=1)
    agg.columns = names
    
    # 删除缺失值
    if dropnan:
        agg.dropna(inplace=True)
    return agg
```

#### 3.1.2 时间特征排序
```python
# 按时间顺序排序
data = data.sort_values(by=["年份", "月份"])
data = data.reset_index().iloc[:, 1:]
```

### 3.2 分类特征编码
#### 3.2.1 独热编码（One-Hot Encoding）
```python
# 对字符串类型的分类变量进行独热编码
data_encoded = pd.get_dummies(data)
```

#### 3.2.2 标签编码
适用于有序分类变量的编码处理

### 3.3 数据透视表转换
```python
# 将长格式数据转换为宽格式
pivot_data = data.pivot_table(
    index=["主键列"], 
    columns="分类列", 
    values="数值列"
)
```

## 4. 特征工程阶段

### 4.1 特征选择
#### 4.1.1 基于相关性的特征选择
- 删除高度相关的特征（相关系数>0.95）
- 保留与目标变量相关性高的特征

#### 4.1.2 基于重要性的特征选择
```python
from sklearn.feature_selection import SelectKBest
# 使用SelectKBest方法降维
selector = SelectKBest(k=35)
X_selected = selector.fit_transform(X, y)
```

### 4.2 特征降维
#### 4.2.1 主成分分析（PCA）
```python
from sklearn.decomposition import PCA
# 保留99%的信息
pca = PCA(n_components=0.99)
X_pca = pca.fit_transform(X)
```

### 4.3 特征合并
将多个数据源按照共同键进行合并
```python
# 多表连接
merged_data = pd.merge(data1, data2, on=["共同列1", "共同列2"])
```

## 5. 数据标准化阶段

### 5.1 标准化处理
```python
from sklearn.preprocessing import StandardScaler
# Z-score标准化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
y_scaled = scaler.fit_transform(y)
```

### 5.2 归一化处理
```python
from sklearn.preprocessing import MinMaxScaler
# 最小-最大归一化
minmax_scaler = MinMaxScaler()
X_normalized = minmax_scaler.fit_transform(X)
```

## 6. 数据集划分阶段

### 6.1 训练集测试集划分
```python
from sklearn.model_selection import train_test_split
# 通常划分比例：80%训练，20%测试
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

### 6.2 时间序列数据划分
对于时间序列数据，需要按时间顺序划分，避免数据泄漏

### 6.3 数据打乱
```python
# 对非时间序列数据进行随机打乱
data_shuffled = data.sample(frac=1).reset_index(drop=True)
```

## 7. 数据验证阶段

### 7.1 数据质量检查
- 检查处理后的数据维度
- 验证数据类型正确性
- 确认无缺失值或异常值

### 7.2 数据一致性检查
- 确保训练集和测试集的特征一致
- 验证标准化参数的正确应用

## 8. 流程总结

### 8.1 完整流程示例
```python
# 1. 数据读取和基本分析
data = pd.read_excel("数据文件.xlsx")
print(data.describe())
print(data.info())

# 2. 数据清洗
data = data.dropna()  # 删除缺失值
data = data.drop_duplicates()  # 删除重复值

# 3. 特征工程
# 相关性分析
corr_matrix = data.corr()
# 删除高相关特征
high_corr_pairs = [(col1, col2) for col1 in corr_matrix.columns 
                   for col2 in corr_matrix.columns 
                   if abs(corr_matrix.loc[col1, col2]) > 0.95 and col1 != col2]

# 4. 数据转换
# 时间序列转换（如适用）
if is_time_series:
    data_supervised = series_to_supervised(data, n_in=72, n_out=1)

# 分类编码
data_encoded = pd.get_dummies(data)

# PCA降维
pca = PCA(n_components=0.99)
X_pca = pca.fit_transform(X)

# 5. 数据标准化
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# 6. 数据集划分
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_scaled, test_size=0.2, random_state=42
)
```

### 8.2 注意事项
1. **时间序列数据**：必须按时间顺序处理，避免未来信息泄漏
2. **标准化顺序**：先划分数据集，再进行标准化，避免数据泄漏
3. **特征工程**：根据具体业务场景选择合适的特征工程方法
4. **数据验证**：每个步骤后都要验证数据的正确性和完整性
5. **参数保存**：保存标准化等预处理的参数，用于新数据的预处理

### 8.3 适用场景
- 时间序列预测问题
- 多变量回归分析
- 分类问题
- 聚类分析
- 机器学习建模前的数据准备

本模板提供了数据预处理的标准化流程，可根据具体项目需求进行调整和优化。 