# SVM在论文中的描述

## 1. 摘要中的描述

构建了**基于分类任务的概率预测模型**,分别对比了k近邻算法,支持向量机分类器,随机森林分类器和梯度提升决策树,利用每个模型输出的置信度作为最终的概率预测。

## 2. 问题一中的描述

### 2.1 模型选择

常见的分类模型有 k 近邻算法,支持向量机分类器,随机森林分类器和梯度提升决策树。本文通过对比这四种模型,利用 K 则交叉验证方法选择出其中最优的模型。

### 2.2 支持向量机分类器详细介绍

2. **支持向量机分类器**:是在分类与回归分析中分析数据的监督式学习模型与相关的学 习算法。SVM 可以对线性可分和非线性可分数据集进行处理。对于线性可分数据集,SVM 可以通过硬间隔最大化,学习线性分类器,即线性可分支持向量机;对于近似线性可分的 数据集,SVM 可以通过软间隔最大化,学习线性分类器,即线性支持向量机;对于不可分 数据集,SVM 则通过核技巧和软间隔最大化,学习非线性分类器,即非线性支持向量机。

在 SVM 中,决策函数的值取决于样本与决策边界(超平面)的距离。正类样本距离 决策边界越远,负类样本距离决策边界越远,它们的决策函数值就越大。因此,在本文中,

# 将决策函数的值表示样本被分类为正类的置信度。

## 3. 消融实验结果

在消融实验表格中，支持向量机的表现为：

| 实验组 | K 近邻 | 支持向量机        | 随机森林         | 梯度提升机        | 相关性分析 | 权重函数         | 网格搜素         | MAE    | MSE     | $R^2$   |
|-----|------|--------------|--------------|--------------|-------|--------------|--------------|--------|---------|---------|
| В   | ×    | $\checkmark$ | ×            | ×            | ×     | ×            | ×            | 0.3232 | 0.1432  | 0.2277  |

## 4. 问题三中的描述

### 4.1 对比方法

为了验证 Stacking 集成算法的有效性,我们比较问题一中所使用的分类模型,包括有 k 近邻算法,支持向量机分类器,随机森林分类器和梯度提升决策树。为了公平对比,所 有模型都使用相同的变量,相同的数据增强手段和同样次数的 K 则交叉验证。

### 4.2 实验结果对比

在问题三的分类模型指标对比中：

| 分类模型     | 精确率   | 召回率   |
|----------|-------|-------|
| 支持向量机分类器 | 0.763 | 0.691 |

在加入随访数据的对比实验中：

|         | 分类模型     | 精确率   | 召回率   |
|---------|----------|-------|-------|
| 未加入随访数据 | 支持向量机分类器 | 0.763 | 0.691 |
| 加入随访数据  | 支持向量机分类器 | 0.793 | 0.831 | 