#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
éšæœºæ£®æ—ç®—æ³•ç²¾ç®€æ¨¡æ¿ - åŸºäºã€Šå‡ºè¡€æ€§è„‘å’ä¸­ä¸´åºŠæ™ºèƒ½è¯Šç–—å»ºæ¨¡ã€‹è®ºæ–‡å®ç°

ç²¾ç®€ç‰ˆæœ¬ï¼ŒåªåŒ…å«æ ¸å¿ƒåŠŸèƒ½ï¼šè®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼°
æ”¯æŒåˆ†ç±»å’Œå›å½’ä»»åŠ¡
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    mean_absolute_error, mean_squared_error, r2_score
)
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.datasets import make_classification, make_regression
import warnings
warnings.filterwarnings('ignore')


class RandomForestTemplate:
    """
    éšæœºæ£®æ—ç®—æ³•ç²¾ç®€æ¨¡æ¿ç±»
    
    åŸºäºè®ºæ–‡ã€Šå‡ºè¡€æ€§è„‘å’ä¸­ä¸´åºŠæ™ºèƒ½è¯Šç–—å»ºæ¨¡ã€‹ä¸­çš„éšæœºæ£®æ—å®ç°
    åªåŒ…å«æ ¸å¿ƒåŠŸèƒ½ï¼šè®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼°
    """
    
    def __init__(self, task_type='classification', n_estimators=100, 
                 max_depth=None, random_state=42):
        """
        åˆå§‹åŒ–éšæœºæ£®æ—æ¨¡å‹
        
        å‚æ•°ï¼š
        - task_type: str, ä»»åŠ¡ç±»å‹ ('classification' æˆ– 'regression')
        - n_estimators: int, å†³ç­–æ ‘æ•°é‡ï¼Œé»˜è®¤100
        - max_depth: int, æ ‘çš„æœ€å¤§æ·±åº¦ï¼Œé»˜è®¤None
        - random_state: int, éšæœºç§å­ï¼Œç¡®ä¿å¯é‡å¤æ€§
        """
        self.task_type = task_type
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.random_state = random_state
        
        # åˆå§‹åŒ–æ¨¡å‹
        if self.task_type == 'classification':
            self.model = RandomForestClassifier(
                n_estimators=self.n_estimators,
                max_depth=self.max_depth,
                random_state=self.random_state,
                n_jobs=-1
            )
        else:  # regression
            self.model = RandomForestRegressor(
                n_estimators=self.n_estimators,
                max_depth=self.max_depth,
                random_state=self.random_state,
                n_jobs=-1
            )
        
        # æ•°æ®é¢„å¤„ç†å™¨
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.is_fitted = False
    
    def fit(self, X, y):
        """
        è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
        
        å‚æ•°ï¼š
        - X: array-like, è®­ç»ƒç‰¹å¾
        - y: array-like, è®­ç»ƒæ ‡ç­¾
        """
        print("å¼€å§‹è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...")
        
        # æ•°æ®é¢„å¤„ç†
        if isinstance(X, pd.DataFrame):
            X = X.values
        X_processed = self.scaler.fit_transform(X)
        
        if self.task_type == 'classification':
            y_processed = self.label_encoder.fit_transform(y)
        else:
            y_processed = np.array(y)
        
        # è®­ç»ƒæ¨¡å‹
        self.model.fit(X_processed, y_processed)
        self.is_fitted = True
        
        print(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        print(f"- ä»»åŠ¡ç±»å‹: {self.task_type}")
        print(f"- å†³ç­–æ ‘æ•°é‡: {self.n_estimators}")
        print(f"- è®­ç»ƒæ ·æœ¬æ•°: {len(X_processed)}")
    
    def predict(self, X):
        """
        æ¨¡å‹é¢„æµ‹
        
        å‚æ•°ï¼š
        - X: array-like, æµ‹è¯•ç‰¹å¾
        
        è¿”å›ï¼š
        - predictions: é¢„æµ‹ç»“æœ
        """
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()æ–¹æ³•")
        
        # æ•°æ®é¢„å¤„ç†
        if isinstance(X, pd.DataFrame):
            X = X.values
        X_processed = self.scaler.transform(X)
        
        # é¢„æµ‹
        predictions = self.model.predict(X_processed)
        
        # åˆ†ç±»ä»»åŠ¡éœ€è¦é€†è½¬æ¢æ ‡ç­¾
        if self.task_type == 'classification':
            predictions = self.label_encoder.inverse_transform(predictions)
        
        return predictions
    
    def predict_proba(self, X):
        """
        é¢„æµ‹æ¦‚ç‡ï¼ˆä»…åˆ†ç±»ä»»åŠ¡ï¼‰
        
        åŸºäºè®ºæ–‡ä¸­çš„ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•ï¼š
        "åˆ©ç”¨å¤šæ•°æŠ•ç¥¨çš„ç»“æœæ•°å æ€»æŠ•ç¥¨æ•°çš„æ¯”ä¾‹ä½œä¸ºç½®ä¿¡åº¦"
        
        å‚æ•°ï¼š
        - X: array-like, æµ‹è¯•ç‰¹å¾
        
        è¿”å›ï¼š
        - probabilities: é¢„æµ‹æ¦‚ç‡
        """
        if self.task_type != 'classification':
            raise ValueError("æ¦‚ç‡é¢„æµ‹ä»…é€‚ç”¨äºåˆ†ç±»ä»»åŠ¡")
        
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()æ–¹æ³•")
        
        # æ•°æ®é¢„å¤„ç†
        if isinstance(X, pd.DataFrame):
            X = X.values
        X_processed = self.scaler.transform(X)
        
        # é¢„æµ‹æ¦‚ç‡
        probabilities = self.model.predict_proba(X_processed)
        
        return probabilities
    
    def evaluate(self, X_test, y_test):
        """
        æ¨¡å‹è¯„ä¼°
        
        åŸºäºè®ºæ–‡ä¸­ä½¿ç”¨çš„è¯„ä¼°æŒ‡æ ‡ï¼š
        - åˆ†ç±»ä»»åŠ¡ï¼šç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°ã€å‡†ç¡®ç‡
        - å›å½’ä»»åŠ¡ï¼šMAEã€MSEã€RMSEã€RÂ²
        
        å‚æ•°ï¼š
        - X_test: array-like, æµ‹è¯•ç‰¹å¾
        - y_test: array-like, æµ‹è¯•æ ‡ç­¾
        
        è¿”å›ï¼š
        - metrics: dict, è¯„ä¼°æŒ‡æ ‡
        """
        predictions = self.predict(X_test)
        
        if self.task_type == 'classification':
            # åˆ†ç±»æŒ‡æ ‡
            accuracy = accuracy_score(y_test, predictions)
            precision = precision_score(y_test, predictions, average='weighted', zero_division=0)
            recall = recall_score(y_test, predictions, average='weighted', zero_division=0)
            f1 = f1_score(y_test, predictions, average='weighted', zero_division=0)
            
            metrics = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1
            }
            
            print("=== åˆ†ç±»æ¨¡å‹è¯„ä¼°ç»“æœ ===")
            print(f"å‡†ç¡®ç‡ (Accuracy): {accuracy:.4f}")
            print(f"ç²¾ç¡®ç‡ (Precision): {precision:.4f}")
            print(f"å¬å›ç‡ (Recall): {recall:.4f}")
            print(f"F1åˆ†æ•°: {f1:.4f}")
        
        else:
            # å›å½’æŒ‡æ ‡ï¼ˆè®ºæ–‡ä¸­ä½¿ç”¨çš„æŒ‡æ ‡ï¼‰
            mae = mean_absolute_error(y_test, predictions)
            mse = mean_squared_error(y_test, predictions)
            rmse = np.sqrt(mse)
            r2 = r2_score(y_test, predictions)
            
            metrics = {
                'mae': mae,
                'mse': mse,
                'rmse': rmse,
                'r2': r2
            }
            
            print("=== å›å½’æ¨¡å‹è¯„ä¼°ç»“æœ ===")
            print(f"å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.4f}")
            print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.4f}")
            print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.4f}")
            print(f"å†³å®šç³»æ•° (RÂ²): {r2:.4f}")
        
        return metrics


def demo_classification():
    """åˆ†ç±»ä»»åŠ¡æ¼”ç¤º"""
    print("=" * 50)
    print("éšæœºæ£®æ—åˆ†ç±»ä»»åŠ¡æ¼”ç¤º")
    print("=" * 50)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    X, y = make_classification(
        n_samples=1000, n_features=20, n_informative=15,
        n_classes=2, weights=[0.77, 0.23],  # æ¨¡æ‹Ÿç±»åˆ«ä¸å¹³è¡¡
        random_state=42
    )
    
    # æ•°æ®åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
    rf_clf = RandomForestTemplate(
        task_type='classification',
        n_estimators=100,
        max_depth=7,
        random_state=42
    )
    
    # è®­ç»ƒ
    rf_clf.fit(X_train, y_train)
    
    # é¢„æµ‹
    predictions = rf_clf.predict(X_test)
    probabilities = rf_clf.predict_proba(X_test[:5])
    
    print("\nå‰5ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ:")
    for i in range(5):
        print(f"æ ·æœ¬{i+1}: é¢„æµ‹ç±»åˆ«={predictions[i]}, "
              f"ç½®ä¿¡åº¦=[{probabilities[i][0]:.3f}, {probabilities[i][1]:.3f}]")
    
    # è¯„ä¼°
    print("\næ¨¡å‹è¯„ä¼°:")
    metrics = rf_clf.evaluate(X_test, y_test)
    
    return rf_clf, metrics


def demo_regression():
    """å›å½’ä»»åŠ¡æ¼”ç¤º"""
    print("=" * 50)
    print("éšæœºæ£®æ—å›å½’ä»»åŠ¡æ¼”ç¤º")
    print("=" * 50)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    X, y = make_regression(
        n_samples=800, n_features=15, n_informative=10,
        noise=0.1, random_state=42
    )
    
    # æ•°æ®åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )
    
    # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
    rf_reg = RandomForestTemplate(
        task_type='regression',
        n_estimators=100,
        max_depth=None,
        random_state=42
    )
    
    # è®­ç»ƒ
    rf_reg.fit(X_train, y_train)
    
    # é¢„æµ‹
    predictions = rf_reg.predict(X_test)
    
    print(f"\nå‰5ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ:")
    for i in range(5):
        print(f"æ ·æœ¬{i+1}: çœŸå®å€¼={y_test[i]:.3f}, é¢„æµ‹å€¼={predictions[i]:.3f}")
    
    # è¯„ä¼°
    print("\næ¨¡å‹è¯„ä¼°:")
    metrics = rf_reg.evaluate(X_test, y_test)
    
    return rf_reg, metrics


if __name__ == "__main__":
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ¼”ç¤ºç¨‹åº"""
    print("éšæœºæ£®æ—ç®—æ³•ç²¾ç®€æ¨¡æ¿æ¼”ç¤º")
    print("åŸºäºã€Šå‡ºè¡€æ€§è„‘å’ä¸­ä¸´åºŠæ™ºèƒ½è¯Šç–—å»ºæ¨¡ã€‹è®ºæ–‡å®ç°")
    print("=" * 60)
    
    # æ¼”ç¤º1ï¼šåˆ†ç±»ä»»åŠ¡
    try:
        rf_clf, clf_metrics = demo_classification()
        print("\nâœ… åˆ†ç±»ä»»åŠ¡æ¼”ç¤ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ åˆ†ç±»ä»»åŠ¡æ¼”ç¤ºå¤±è´¥: {e}")
    
    print("\n" + "=" * 60)
    
    # æ¼”ç¤º2ï¼šå›å½’ä»»åŠ¡
    try:
        rf_reg, reg_metrics = demo_regression()
        print("\nâœ… å›å½’ä»»åŠ¡æ¼”ç¤ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ å›å½’ä»»åŠ¡æ¼”ç¤ºå¤±è´¥: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
    
    # ä½¿ç”¨è¯´æ˜
    print("\nğŸ“– ä½¿ç”¨è¯´æ˜:")
    print("1. åˆ†ç±»ä»»åŠ¡: RandomForestTemplate(task_type='classification')")
    print("2. å›å½’ä»»åŠ¡: RandomForestTemplate(task_type='regression')")
    print("3. æ ¸å¿ƒæ–¹æ³•: fit(), predict(), evaluate()")
    print("4. åˆ†ç±»é¢å¤–: predict_proba() - æ¦‚ç‡é¢„æµ‹") 