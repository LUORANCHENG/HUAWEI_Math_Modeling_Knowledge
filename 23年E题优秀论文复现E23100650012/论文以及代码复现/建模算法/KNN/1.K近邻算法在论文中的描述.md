# K近邻算法描述

## 1. 基本概念

k 近邻算法: 是一种基本的分类与回归算法,核心功能是解决有监督的分类问题。K 近邻算法不具有显式的学习过程,属于"惰性学习"的一种。且该算法属于非参数学习算法,不需要学习任何参数。该算法的核心思想是通过测量不同特征值之间的距离进行分类。 对于输入的预测向量,寻找与其最邻近的 k 个向量,如果这 k 个向量属于同一类或者大部 分属于同一类,那么 x 就和这 k 个向量大部分所在的类分为一类。在本问中,需要输出分 类结果的置信度,因此考虑使用次数出现最多的类别数目除以 k,具体的计算置信度的流 程如下为:

## 2. 算法流程

Algorithm 2 K 近邻算法计算分类置信度

1: **输入:** 训练数据集  $D = \{(\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), \dots, (\mathbf{x}_n, y_n)\},$ 待分类样本  $\mathbf{x}$ , 近邻数 K。

- 2: **输出:** 样本 x 的类别 y。
- 3: for i = 1 to n do
- 4: 计算样本 **x** 与训练集中样本 **x**<sub>i</sub> 的距离  $d_i = ||\mathbf{x} \mathbf{x}_i||_{\circ}$
- 5: **end for**
- 6: 按照距离 d<sub>i</sub> 升序排序训练集中的样本。
- 7: 选取距离最近的 K 个样本,记为  $\mathcal{N}_{K}(\mathbf{x})$ 。
- 8: 计算  $\mathcal{N}_{K}(\mathbf{x})$  中每个类别出现的次数。
- 9: 将样本 **x** 分类为出现次数最多的类别,即  $y = \arg \max_c \sum_{\mathbf{x}_i \in \mathcal{N}_K(\mathbf{x})} I(y_i = c)$ ,其中  $I \in I$  指示函数。
- 10: 样本的置信度为  $p_c = (\max_c \sum_{\mathbf{x}_i \in \mathcal{N}_K(\mathbf{x})} I(y_i = c))/k$

## 3. 实验应用

在本文的研究中，k近邻算法被用作对比模型之一，与支持向量机分类器、随机森林分类器和梯度提升决策树进行性能比较。

### 3.1 消融实验结果

在消融实验中，k近邻算法的表现如下：

| 实验组 | K 近邻 | MAE    | MSE     | $R^2$   |
|-----|------|--------|---------|---------|
| А   | ✓    | 0.3107 | 0.1606  | 0.1344  |

### 3.2 模型比较结果

#### 问题三-a 的结果
| 分类模型     | 精确率   | 召回率   |
|----------|-------|-------|
| k 近邻算法   | 0.652 | 0.568 |

#### 问题三-b 的结果对比
|         | 分类模型     | 精确率   | 召回率   |
|---------|----------|-------|-------|
| 未加入随访数据 | k 近邻算法   | 0.652 | 0.568 |
| 加入随访数据  | k 近邻算法   | 0.692 | 0.613 |

## 4. 特征权重函数选择中的应用

**特征权重函数的选择:**在本问中,设计了两种权重函数,分别是指数函数和幂函数。 此目的是为了解决"首次影像检查的时间"差异性比较大的问题。首先,我们单独地利用 K则交叉验证 +KNN的方法,对函数和参数 K 进行选择,最终确定当使用幂函数形式且 参数 k 选择 0.7 时, KNN 模型获得了最佳的表现。其次,利用上述的结论,将权重函数的 方法加入了梯度提升机模型中,进行了实验组 D 和 F 的对比,不难发现,权重函数的引入 带来了模型性能的提升。

## 5. 模型选择结论

**模型的选择:**前四组实验分别对比四种模型的性能。为了公平直观地进行对比,并没 有对四种方法进行变量筛选等操作。从评价指标来看,梯度提升机获得了最佳的表现。在 本问中,发生血肿扩张的人数为 23 人,未发生血肿扩张的为 77 人,存在着一定情况的类 别不平衡问题,同时,经过对数据的审视,发现原始数据也存在着一定量的离散变量。而 梯度提升机在处理类别偏差和混合数据类型具有一定的优势,故最终选择梯度提升机作为 第一问的概率预测基础模型。 