# Stacking集成算法在论文中的描述

## 1. 摘要中的描述

问题三:问题 a 要求构建预测模型,预测患者 90 天 mRS 评分。本题没有限制特征的 数量,基于对模型简单、通用、特征提取能力强大的考量,构建了基于 Stacking 的分类模 型。首先对 mRS 评分的分布进行数据分析,发现存在一定程度的类别不平衡现象,为此, 采用 Borderline-SMOTE 过采样算法进行处理;实验部分,通过与 k 近邻算法,支持向量 机分类器和随机森林分类器的对比,Stacking 获得了最佳的效果,准确率和召回分别达到 了 83.5% 和 82.1%。问题 b 是问题 a 的一个延申,需要在问题 a 的基础上加上随访数据, 但随访数据存在着随访检查数量不统一的问题。为此,对随访数据进行时间和空间上的解 耦,量化出了五个指标,分别是发病持续时间,血肿的最大体积,水肿的最大体积,血肿 扩张的持续时间和水肿扩张的持续时间。最终,结合问题 a 的模型和数据进行训练,精确 率和召回率分别由 83.5% 和 82.1% 提升到了 92.3% 和 89.4%。

## 2. 关键字

基于 Stacking 的分类模型

## 3. 问题分析

对于本题,其实是需要建立一个七分类模型。但难点在于数据量较少,若使用特征提 取能力强大的神经网络建模,有可能出现过拟合的情况,因此需要建立一个表达能力强同 时容量较少的模型。本文使用 K 则交叉验证建立基于 Stacking 的回归模型。

## 4. 基于 Stacking 的分类模型建立

Stacking 方法是一种层级模型集成框架,它在各种机器学习任务中具有提高模型准确 性和增强泛化能力的潜力。该方法通过组合多个基学习器来执行学习任务。以两层集成为 例,首先,将数据集分为训练集和测试集。使用训练集来训练多个初级学习器,这些初级 学习器可以是不同的机器学习模型。然后,使用这些初级学习器来对测试集进行预测,并 将它们的输出值作为下一阶段训练的输入。最终,使用测试集的真实标签作为输出值,用 于训练次级学习器,也称为元学习器 (meta-learner)。Stacking 的关键思想在于,由于初级 学习器和次级学习器在两个不同的数据集上进行训练,可以一定程度上防止过拟合。这种 分层结构有助于提高模型的性能,使模型能够更好地捕获数据的复杂关系,提高泛化能力。

## 5. 对比方法

为了验证 Stacking 集成算法的有效性,我们比较问题一中所使用的分类模型,包括有 k 近邻算法,支持向量机分类器,随机森林分类器和梯度提升决策树。为了公平对比,所 有模型都使用相同的变量,相同的数据增强手段和同样次数的 K 则交叉验证。

## 6. 实验结果

### 6.1 问题 a 的实验结果

针对患者 90 天 mRS 评分的预测问题,我们对比了五种方法,具体性能见下表。不难 发现基于 Stacking 的分类模型表现出了最佳的效果,准确和召回均高于 80%。

| 分类模型     | 精确率   | 召回率   |
|----------|-------|-------|
| k 近邻算法   | 0.652 | 0.568 |
| 支持向量机分类器 | 0.763 | 0.691 |
| 随机森林分类器  | 0.738 | 0.678 |
| 梯度提升决策树  | 0.781 | 0.731 |
| Stacking | 0.835 | 0.821 |

### 6.2 问题 b 的实验结果

在本问中,将随访数据的量化结果与问题 a 的变量合并,作为模型的训练数据。针对 患者 90 天 mRS 评分的预测问题,我们横行对比了加入随访数据和不加随访数据的指标对 比,纵向对比了不同方法之前的优劣性,相关的指标记录在下表中。不难发现,加入了随 访数据的量化结果后,大部分模型都取得了一定程度的指标提高。此外,Stacking 的分类 模型表现出了最佳的效果,准确和召回分别达到了 92.3% 和 89.4%。

|         | 分类模型     | 精确率   | 召回率   |
|---------|----------|-------|-------|
| 未加入随访数据 | k 近邻算法   | 0.652 | 0.568 |
|         | 支持向量机分类器 | 0.763 | 0.691 |
|         | 随机森林分类器  | 0.738 | 0.678 |
|         | 梯度提升决策树  | 0.781 | 0.731 |
|         | Stacking | 0.835 | 0.821 |
| 加入随访数据  | k 近邻算法   | 0.692 | 0.613 |
|         | 支持向量机分类器 | 0.793 | 0.831 |
|         | 随机森林分类器  | 0.798 | 0.818 |
|         | 梯度提升决策树  | 0.868 | 0.838 |
|         | Stacking | 0.923 | 0.894 | 