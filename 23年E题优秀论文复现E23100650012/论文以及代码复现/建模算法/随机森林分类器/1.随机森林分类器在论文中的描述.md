# 随机森林分类器在论文中的描述

## 1. 摘要部分的描述

构建了**基于分类任务的概率预测模型**,分别对比了k近邻算法,支持向量机分类器,随机森林分类器和梯度提升决策树,利用每个模型输出的置信度作为最终的概率预测。

实验部分,通过与 k 近邻算法,支持向量机分类器和随机森林分类器的对比,Stacking 获得了最佳的效果,准确率和召回分别达到了 83.5% 和 82.1%。

## 2. 问题一中的描述

常见的分类模型有 k 近邻算法,支持向量机分类器,随机森林分类器和梯度提升决策树。本文通过对比这四种模型,利用 K 则交叉验证方法选择出其中最优的模型。

### 2.1 随机森林的详细描述

3. 随机森林: 是一种组合分类器,它以 K 个决策树为基本分类器进行集成学习,对预测输出进行结合。其中每个决策树之间没有依赖关系,在进行分类任务时,输出的分类结果是由每个决策树的分类结果经过简单投票后所决定。故在本问中,利用多数投票的结果数占总投票数的比例作为置信度,具体的计算如下

| Alg | orithm 3 基于随机森林的分类置信度估计                          |
|-----|--------------------------------------------------|
| 1:  | **输入:** 随机森林模型 RF,测试样本 x。                     |
| 2:  | **输出** :样本 $x$ 的分类置信度估计 $P(y \mathbf{x})$ 。   |
| 3:  | 初始化类别概率估计数组 $P(y \mathbf{x})$ 为每个类别 $y$          |
| 4:  | for 每棵树 $T$ 在随机森林模型 $RF$ 中 do                    |
| 5:  | 进行随机森林模型中的树 T 上的样本分类预测                           |
| 6:  | 记录分类结果 yr                                        |
| 7:  | 增加 $y_T$ 对应的类别概率估计 $P(y_T   \mathbf{x})$         |
| 8:  | end for                                          |
| 9:  | 对于每个类别 $y$ ,计算平均类别概率估计 $P(y \mathbf{x})$ 作为分类置信度 |

 10: **返回:** 样本 **x** 的分类置信度估计 *P*(*y*|**x**),其中 *y* 表示类别。

 

### 2.2 梯度提升决策树与随机森林的比较

**与随机森林的原理类似,在本问中,对多个基学习器的结果进行整合,** 以获得最终的分类结果和相应的置信度预测。

### 2.3 实验结果对比

| 实验组 | K 近邻 | 支持向量机        | 随机森林         | 梯度提升机        | 相关性分析 | 权重函数         | 网格搜素         | MAE    | MSE     | $R^2$   |
|-----|------|--------------|--------------|--------------|-------|--------------|--------------|--------|---------|---------|
| А   | ✓    | ×            | ×            | ×            | ×     | ×            | ×            | 0.3107 | 0.1606  | 0.1344  |
| В   | ×    | $\checkmark$ | ×            | ×            | ×     | ×            | ×            | 0.3232 | 0.1432  | 0.2277  |
| С   | ×    | ×            | $\checkmark$ | ×            | ×     | ×            | ×            | 0.1453 | 0.0292  | 0.8425  |
| D   | ×    | ×            | ×            | $\checkmark$ | ×     | ×            | ×            | 0.0924 | 0.0083  | 0.9273  |
| Е   | ×    | ×            | ×            | $\checkmark$ | ~     | ×            | ×            | 0.0734 | 0.0083  | 0.9273  |
| F   | ×    | ×            | ×            | $\checkmark$ | ×     | $\checkmark$ | ×            | 0.0718 | 0.0072  | 0.9374  |
| G   | ×    | ×            | ×            | $\checkmark$ | ✓     | $\checkmark$ | $\checkmark$ | 0.0524 | 0.00477 | 0.97429 |

## 3. 问题二中的描述（作为回归模型）

为了探究最适合于本问的拟合模型,分别选取了线性拟合和非线性拟合的方法进行对比,具体有线性回归、随机森林、梯度提升回归和决策树回归四种模型。区别于第一问的分类模型,本问中使用这些模型进行回归拟合。

### 3.1 随机森林回归的描述

# 2. 随机森林

随机森林是一种集成学习方法,它基于决策树构建多个弱学习器,并将它们组合成一个强学习器。每个决策树都是在不同的样本子集和特征子集上进行训练的,以增加模型的多样性。当我们使用随机森林进行曲线拟合时,目标是找到一个由多个决策树组成的集成模型,能够拟合输入特征 *X* 和因变量 *Y* 之间的非线性关系。这允许我们建立一个复杂的曲线模型,可以更好地捕获数据中的变化模式。

### 3.2 随机森林回归的实验结果

| 模型     | MAE        | RMSE       | $R^2$  |
|--------|------------|------------|--------|
| 线性模型   | 19585.8539 | 26000.3398 | 0.0050 |
| 随机森林   | 9082.4880  | 12374.9406 | 0.7746 |
| 梯度提升回归 | 13465.3358 | 21747.4794 | 0.5450 |
| 决策树    | 1838.8871  | 5114.2279  | 0.9615 |

为了更直观地对比各个模型的预测结果,我们将全部患者的检查时间作为横坐标,对应水肿体积预测值与真实值的残差作为纵坐标,画出了各个模型的残差图,如下图所示,可以发现,线性模型、随机森林以及梯度提升回归模型都对训练集欠拟合,模型的性能不如梯度提升模型。

### 3.3 亚组分析中的应用

分别对以上三个亚组进行拟合模型的构建,为了便于对比,模型和变量选择同问题 a。在进行线性回归、随机森林模型、梯度提升回归、决策树回归模型拟合后,发现决策树回归模型的效果最好,拟合曲线如图 12,且亚组拟合模型评价结果如表 11。

## 4. 问题三中的描述

### 4.1 类别不平衡处理的描述

- 使用集成模型:使用集成模型,如随机森林或梯度提升树,这些模型对类别不平衡问题具有一定的鲁棒性。

### 4.2 对比实验中的应用

为了验证 Stacking 集成算法的有效性,我们比较问题一中所使用的分类模型,包括有 k 近邻算法,支持向量机分类器,随机森林分类器和梯度提升决策树。为了公平对比,所有模型都使用相同的变量,相同的数据增强手段和同样次数的 K 则交叉验证。

### 4.3 分类性能对比结果

| 分类模型     | 精确率   | 召回率   |
|----------|-------|-------|
| k 近邻算法   | 0.652 | 0.568 |
| 支持向量机分类器 | 0.763 | 0.691 |
| 随机森林分类器  | 0.738 | 0.678 |
| 梯度提升决策树  | 0.781 | 0.731 |
| Stacking | 0.835 | 0.821 |

### 4.4 加入随访数据后的性能对比

|         | 分类模型     | 精确率   | 召回率   |
|---------|----------|-------|-------|
| 未加入随访数据 | k 近邻算法   | 0.652 | 0.568 |
|         | 支持向量机分类器 | 0.763 | 0.691 |
|         | 随机森林分类器  | 0.738 | 0.678 |
|         | 梯度提升决策树  | 0.781 | 0.731 |
|         | Stacking | 0.835 | 0.821 |
| 加入随访数据  | k 近邻算法   | 0.692 | 0.613 |
|         | 支持向量机分类器 | 0.793 | 0.831 |
|         | 随机森林分类器  | 0.798 | 0.818 |
|         | 梯度提升决策树  | 0.868 | 0.838 |
|         | Stacking | 0.923 | 0.894 | 