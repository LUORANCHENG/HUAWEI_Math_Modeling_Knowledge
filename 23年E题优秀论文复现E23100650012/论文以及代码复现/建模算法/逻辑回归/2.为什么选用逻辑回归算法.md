# 为什么选用逻辑回归算法

## 1. 问题背景分析

根据论文第6.1节的问题分析，作者面临的是一个**七分类预测问题**——预测患者90天mRS评分（评分范围从0到6）。作者明确指出了选择模型时的核心难点：

> "对于本题，其实是需要建立一个七分类模型。但难点在于数据量较少，若使用特征提取能力强大的神经网络建模，有可能出现过拟合的情况，因此需要建立一个表达能力强同时容量较少的模型。"

## 2. 逻辑回归在Stacking框架中的作用

### 2.1 作为元学习器的选择

在论文的Stacking集成框架中，逻辑回归被选作**元学习器（meta-learner）**，其主要作用是：

- **整合多个基学习器的预测结果**：将K近邻、SVM、随机森林、梯度提升树等基学习器的输出作为输入
- **最终分类决策**：基于基学习器的预测结果做出最终的mRS评分预测

### 2.2 代码实现体现

```python
estimators = [('rf', RandomForestClassifier(n_jobs=-1)), 
              ('svc', SVC(kernel="rbf", probability=True)), 
              ('gdbt', GradientBoostingClassifier()),
              ('knn', KNeighborsClassifier(n_jobs=-1))]

StackingClassifier(estimators=estimators, 
                  final_estimator=LogisticRegression())
```

## 3. 选择逻辑回归的核心原因

### 3.1 小样本数据的适应性

**数据量限制**：
- 论文中只有前100个患者的数据用于训练
- 在小样本情况下，复杂模型（如神经网络）容易过拟合
- 逻辑回归具有较少的参数，适合小样本训练

### 3.2 模型复杂度的平衡

**"表达能力强同时容量较少"的要求**：
- **表达能力强**：逻辑回归能够处理多分类问题，具有良好的线性可分性
- **容量较少**：参数数量相对较少，模型复杂度适中，不易过拟合

### 3.3 Stacking框架的防过拟合机制

**分层训练的优势**：
- 论文指出："Stacking的关键思想在于，由于初级学习器和次级学习器在两个不同的数据集上进行训练，可以一定程度上防止过拟合"
- 逻辑回归作为次级学习器，在这种分层结构中能够有效利用基学习器的多样性
- 避免了单一复杂模型可能出现的过拟合问题

### 3.4 多分类问题的适用性

**七分类任务的处理**：
- 逻辑回归天然支持多分类问题（通过softmax函数）
- 能够输出每个类别的概率分布，便于解释和分析
- 在医学预测场景中，概率输出具有重要的临床意义

## 4. 实验结果验证

论文实验结果表明，基于Stacking的分类模型（使用逻辑回归作为元学习器）取得了最佳效果：

| 分类模型 | 精确率 | 召回率 |
|---------|--------|--------|
| k近邻算法 | 0.652 | 0.568 |
| 支持向量机分类器 | 0.763 | 0.691 |
| 随机森林分类器 | 0.738 | 0.678 |
| 梯度提升决策树 | 0.781 | 0.731 |
| **Stacking** | **0.835** | **0.821** |

## 5. 总结

作者选择逻辑回归算法的原因可以概括为：

1. **适应小样本环境**：在数据量较少的情况下，逻辑回归不易过拟合
2. **平衡模型复杂度**：既有足够的表达能力处理七分类问题，又保持适度的模型容量
3. **发挥集成优势**：在Stacking框架中作为元学习器，能够有效整合多个基学习器的优势
4. **防止过拟合**：通过分层训练机制，避免了直接使用复杂模型可能带来的过拟合风险
5. **临床适用性**：输出概率分布，便于医学决策的解释和应用

这种选择体现了作者在模型性能、泛化能力和实际应用之间的精心权衡。 