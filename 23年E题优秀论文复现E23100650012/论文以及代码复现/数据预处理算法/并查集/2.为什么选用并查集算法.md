# 为什么选用并查集算法

## 1. 问题背景与挑战

### 1.1 数据特征问题
在经过方差分析剔除非显著性特征后,剩余69个变量。针对剩余变量的可视化结果,发现部分变量的相关系数很高,具有高冗余性,因此需要建立相应的数学模型来处理这一问题。

### 1.2 变量特性分析
由于本题中的变量类型,还存在非连续型变量且不符合正态分布特性,因此选择斯皮尔曼系数进行冗余特征过滤数学建模。

## 2. 选择并查集算法的核心原因

### 2.1 解决高相关性变量问题
- **核心目标**：利用并查集的思想去除掉相关系数高的变量
- **具体作用**：对变量进行冗余过滤，从69个变量减少到47个变量
- **处理对象**：基于斯皮尔曼相关性系数矩阵C，处理相关系数超过阈值Θ的变量对

### 2.2 保证特征变量独立性
某种意义上，任何主要变量均可独立的描述因变量的某方面性质。此时要求主要变量具有一定的独立性。通过并查集算法处理后，变量之间的独立性较好，满足特征变量独立性的要求，也便于后续模型的复用。

### 2.3 提高模型性能
从消融实验结果可以看出：
- 不使用相关性分析的梯度提升机：MAE=0.0924, R²=0.9273
- 使用相关性分析的梯度提升机：MAE=0.0734, R²=0.9273
- 完整方案（包含并查集相关性分析）：MAE=0.0524, R²=0.97429

实验结果表明，并查集算法的引入显著提升了模型的预测精度。

## 3. 并查集算法的适用性优势

### 3.1 算法效率
并查集算法能够高效地处理变量间的分组关系，通过路径压缩和按秩合并等优化技术，在处理大规模相关性矩阵时具有良好的时间复杂度。

### 3.2 逻辑清晰
- 将相关性高的变量归为同一个集合
- 从每个集合中选择代表性变量
- 确保最终选择的变量之间相关性较低

### 3.3 可扩展性
该方法便于后续模型的复用，为不同的机器学习算法提供了高质量的特征输入。

## 4. 实际应用效果

### 4.1 变量筛选效果
- "表1"的患者信息呈现弱相关，故而全部被保留
- "表2"和"表3"的变量保留了27个，有效去除了冗余特征

### 4.2 模型性能提升
通过消融实验验证，基于并查集的高相关性变量过滤模型的引入，使得最终模型的MAE从0.0924降低到0.0524，R²从0.9273提升到0.97429，显著提高了预测精度。

## 5. 总结

作者选择并查集算法的根本原因是为了解决高维特征空间中的冗余问题，确保特征变量的独立性，从而提高机器学习模型的性能。该算法不仅能够有效处理相关性矩阵，还能保证结果的可解释性和可复用性，为后续的特征工程和模型构建奠定了良好的基础。 